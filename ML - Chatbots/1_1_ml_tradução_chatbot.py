# -*- coding: utf-8 -*-
"""1.1 ML- tradução ChatBot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ffnonmv1jL50a4xpot4nQaBer3H8XUgi
"""

from transformers import MarianMTModel, MarianTokenizer

# Carregar modelo para tradução
def carregar_tradutor(lang_pair="Helsinki-NLP/opus-mt-en-pt"):
    tokenizer = MarianTokenizer.from_pretrained(lang_pair)
    model = MarianMTModel.from_pretrained(lang_pair)
    return tokenizer, model

# Função de tradução
def traduzir(texto, tokenizer, model):
    inputs = tokenizer(texto, return_tensors="pt", truncation=True)
    outputs = model.generate(**inputs)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

tokenizer = AutoTokenizer.from_pretrained("unicamp-dl/translation-pt-en-t5")

model = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-pt-en-t5")

pten_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)

pten_pipeline("translate Portuguese to English: Eu gosto de comer arroz.")

tokenizer = AutoTokenizer.from_pretrained("unicamp-dl/translation-en-pt-t5")
model = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-en-pt-t5")

# Cria o pipeline de tradução
enpt_pipeline = pipeline('text2text-generation', model=model, tokenizer=tokenizer)

# Realiza a tradução de um texto do inglês para o português
resultado = enpt_pipeline("translate English to Portuguese: I like to eat rice.")

# Exibe o resultado
print(resultado[0]['generated_text'])

"""Construindo o chatbot"""

# Configuração para tradução português-inglês
tokenizer_pt_en = AutoTokenizer.from_pretrained("unicamp-dl/translation-pt-en-t5")
model_pt_en = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-pt-en-t5")
pten_pipeline = pipeline('text2text-generation', model=model_pt_en, tokenizer=tokenizer_pt_en)

# Configuração para tradução inglês-português
tokenizer_en_pt = AutoTokenizer.from_pretrained("unicamp-dl/translation-en-pt-t5")
model_en_pt = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-en-pt-t5")
enpt_pipeline = pipeline('text2text-generation', model=model_en_pt, tokenizer=tokenizer_en_pt)

# Função do ChatBot
def chatbot(message, mode="pt-en"):
    """
    Chatbot para tradução entre português-inglês e inglês-português.

    Args:
        message (str): Texto de entrada.
        mode (str): Direção da tradução, "pt-en" ou "en-pt".

    Returns:
        str: Texto traduzido.
    """
    if mode == "pt-en":
        result = pten_pipeline(f"translate Portuguese to English: {message}")
    elif mode == "en-pt":
        result = enpt_pipeline(f"translate English to Portuguese: {message}")
    else:
        return "Modo inválido! Use 'pt-en' ou 'en-pt'."

    return result[0]['generated_text']

def selecionar_modo():
    """
    Exibe as opções disponíveis e solicita ao usuário que escolha o modo de tradução.

    Returns:
        str: O modo de tradução escolhido ("pt-en" ou "en-pt").
    """
    print("\nSelecione o modo de tradução:")
    print("1 - Português para Inglês (pt-en)")
    print("2 - Inglês para Português (en-pt)")
    escolha = input("Digite o número da sua escolha: ").strip()

    if escolha == "1":
        return "pt-en"
    elif escolha == "2":
        return "en-pt"
    else:
        print("Escolha inválida! Tente novamente.")
        return selecionar_modo()

# Loop principal do chatbot
while True:
    user_input = input("\nVocê: ")
    if user_input.lower() == "sair":
        print("Encerrando o ChatBot...")
        break

    # Seleção do modo de tradução
    mode = selecionar_modo()

    # Gera a resposta baseada no modo escolhido
    response = chatbot(user_input, mode)
    print(f"ChatBot ({mode}): {response}")

"""# **Criando a interface**"""

!pip install gradio

import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

# Configuração para tradução português-inglês
tokenizer_pt_en = AutoTokenizer.from_pretrained("unicamp-dl/translation-pt-en-t5")
model_pt_en = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-pt-en-t5")
pten_pipeline = pipeline('text2text-generation', model=model_pt_en, tokenizer=tokenizer_pt_en)

# Configuração para tradução inglês-português
tokenizer_en_pt = AutoTokenizer.from_pretrained("unicamp-dl/translation-en-pt-t5")
model_en_pt = AutoModelForSeq2SeqLM.from_pretrained("unicamp-dl/translation-en-pt-t5")
enpt_pipeline = pipeline('text2text-generation', model=model_en_pt, tokenizer=tokenizer_en_pt)

# Função do ChatBot
def chatbot(message, mode):
    """
    Chatbot para tradução entre português-inglês e inglês-português.

    Args:
        message (str): Texto de entrada.
        mode (str): Direção da tradução, "pt-en" ou "en-pt".

    Returns:
        str: Texto traduzido.
    """
    if mode == "pt-en":
        result = pten_pipeline(f"translate Portuguese to English: {message}")
    elif mode == "en-pt":
        result = enpt_pipeline(f"translate English to Portuguese: {message}")
    else:
        return "Modo inválido! Escolha 'pt-en' ou 'en-pt'."

    return result[0]['generated_text']

# Interface com Gradio
def chatbot_interface(message, mode):
    """
    Interface para o chatbot com tradução.

    Args:
        message (str): Mensagem do usuário.
        mode (str): Direção da tradução ("pt-en" ou "en-pt").

    Returns:
        str: Texto traduzido.
    """
    return chatbot(message, mode)

interface = gr.Interface(
    fn=chatbot_interface,
    inputs=[
        gr.Textbox(label="Digite o texto para tradução"),
        gr.Radio(["pt-en", "en-pt"], label="Modo de Tradução", value="pt-en")
    ],
    outputs="text",
    title="Traduzir Textos",
    description="Traduza textos entre Português e Inglês de forma interativa."
)


# Iniciar a aplicação
interface.launch()

!pip freeze > requirements.txt

